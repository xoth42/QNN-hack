# ğŸš€ Team Execution Guide - Quantum CNN Project

## ğŸ“‹ Overview

This guide is for the team members who will run the actual training experiments on powerful machines.

**Project Goal**: Compare classical CNN vs quantum-enhanced CNN on CIFAR-10 to demonstrate quantum advantage.

---

## ğŸ¯ Three Approaches Implemented

### 1. Classical Baseline (Control)
**File**: `cifar10_tinycnn.py`  
**Purpose**: Establish performance benchmark  
**Runtime**: ~15-20 minutes (15 epochs)  
**Command**:
```bash
python cifar10_tinycnn.py
```

### 2. Quanvolutional Preprocessing â­ **RECOMMENDED**
**Files**: `quanvolutional_preprocessing.py`, `train_quanvolutional_cnn.py`  
**Purpose**: Use quantum circuits as preprocessing filters  
**Runtime**: 2-4 hours preprocessing + 15-20 min training  
**Commands**:
```bash
# Step 1: Preprocess (ONE-TIME, can run overnight)
python quanvolutional_preprocessing.py --local --num-samples 10000 --visualize

# Step 2: Train on quantum-preprocessed data
python train_quanvolutional_cnn.py --epochs 15
```

### 3. End-to-End Quantum Hybrid
**File**: `quantum_hybrid_cnn_optimized.py`  
**Purpose**: Quantum layer in training loop  
**Runtime**: ~30-60 minutes per epoch  
**Command**:
```bash
python quantum_hybrid_cnn_optimized.py --local --epochs 5 --quantum-qubits 8 --quantum-layers 4 --batch-size 16
```

---

## ğŸ“Š Recommended Execution Order

### Phase 1: Quick Validation (30 minutes)
Test that everything works before long runs:

```bash
# 1. Verify setup
python verify_setup.py

# 2. Quick classical test (2 epochs)
python cifar10_tinycnn.py  # Edit EPOCHS=2 in file first

# 3. Quick quantum test (1 epoch, 100 samples)
python quanvolutional_preprocessing.py --local --num-samples 100
python train_quanvolutional_cnn.py --epochs 1
```

### Phase 2: Full Experiments (6-8 hours total)

**Run these in order or parallel if you have multiple machines:**

```bash
# Experiment 1: Classical Baseline (15-20 min)
python cifar10_tinycnn.py

# Experiment 2: Quanvolutional (3-4 hours)
python quanvolutional_preprocessing.py --local --num-samples 10000 --visualize
python train_quanvolutional_cnn.py --epochs 15

# Experiment 3: End-to-End Quantum (2-3 hours)
python quantum_hybrid_cnn_optimized.py --local --epochs 5 --quantum-qubits 8 --quantum-layers 4 --batch-size 16

# Experiment 4: Vary quantum configurations (optional, 4-6 hours)
python quantum_hybrid_cnn_optimized.py --local --epochs 5 --quantum-qubits 4 --quantum-layers 2 --batch-size 16
python quantum_hybrid_cnn_optimized.py --local --epochs 5 --quantum-qubits 16 --quantum-layers 4 --batch-size 8
```

### Phase 3: Analysis (5 minutes)

```bash
# Generate all comparison plots and reports
python compare_and_visualize.py
```

---

## ğŸ’» System Requirements

### Minimum:
- **CPU**: 4+ cores
- **RAM**: 8GB
- **Storage**: 5GB free
- **Time**: 6-8 hours for full experiments

### Recommended:
- **CPU**: 8+ cores (faster quantum simulation)
- **RAM**: 16GB
- **GPU**: CUDA-capable (10x faster for classical CNN)
- **Storage**: 10GB free

### Software:
- Python 3.11+
- PyTorch 2.0+
- PennyLane 0.33+
- See `requirements.txt` for full list

---

## ğŸ”§ Setup Instructions

### 1. Clone and Setup Environment

```bash
# Navigate to project
cd QNN-hack

# Install dependencies
pip install -r requirements.txt

# Verify setup
python verify_setup.py
```

### 2. Check Data

```bash
# CIFAR-10 will auto-download on first run
# Verify data directory exists
ls data/
```

### 3. Test Quick Run

```bash
# Run 1 epoch to verify everything works
python cifar10_tinycnn.py  # Edit EPOCHS=1 first
```

---

## ğŸ“ˆ Expected Results

| Approach | Expected Accuracy | Training Time | Key Insight |
|----------|------------------|---------------|-------------|
| Classical | 65-75% | 15-20 min | Baseline |
| Quanvolutional | 68-78% | 3-4 hours total | Quantum preprocessing helps |
| End-to-End | 60-70% | 2-3 hours | Limited by bottleneck |

**Success Criteria**:
- âœ… Quanvolutional > Classical by 2%+ â†’ Quantum advantage!
- âœ… Quanvolutional within 5% of Classical â†’ Competitive
- âœ… Any result is scientifically valuable

---

## ğŸ“ Output Files

All experiments automatically save to `experiments/` directory:

```
experiments/
â”œâ”€â”€ classical/
â”‚   â””â”€â”€ 2025-11-09_HHMMSS_classical_baseline.json
â”œâ”€â”€ quanvolutional/
â”‚   â””â”€â”€ 2025-11-09_HHMMSS_quanvolutional_quantum_preprocessed.json
â”œâ”€â”€ quantum_optimized/
â”‚   â””â”€â”€ 2025-11-09_HHMMSS_quantum_8qubits_4layers.json
â””â”€â”€ analysis/
    â”œâ”€â”€ accuracy_comparison.png
    â”œâ”€â”€ loss_curves.png
    â”œâ”€â”€ training_time_comparison.png
    â”œâ”€â”€ quantum_analysis.png
    â””â”€â”€ summary_report.txt
```

---

## ğŸ› Troubleshooting

### "Out of memory" error
```bash
# Reduce batch size
python quantum_hybrid_cnn_optimized.py --batch-size 8  # or 4
```

### "CUDA out of memory"
```bash
# Use CPU only
export CUDA_VISIBLE_DEVICES=""
python cifar10_tinycnn.py
```

### Quantum preprocessing too slow
```bash
# Start with fewer samples
python quanvolutional_preprocessing.py --local --num-samples 1000

# Then scale up
python quanvolutional_preprocessing.py --local --num-samples 10000
```

### Import errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

---

## ğŸ“Š Monitoring Progress

### Check experiment status:
```bash
# List saved experiments
ls experiments/classical/
ls experiments/quanvolutional/
ls experiments/quantum_optimized/

# View latest results
python -c "import json; print(json.dumps(json.load(open('experiments/classical/latest.json')), indent=2))"
```

### Monitor training:
- Watch console output for epoch progress
- Check `experiments/` folder for saved results
- Training loss should decrease over epochs
- Validation accuracy should increase

---

## ğŸ¯ Deliverables Checklist

After running all experiments, you should have:

- [ ] Classical baseline results (JSON + model)
- [ ] Quanvolutional results (JSON + preprocessed data)
- [ ] End-to-end quantum results (JSON)
- [ ] Comparison plots (4 PNG files)
- [ ] Summary report (TXT file)
- [ ] All code committed to git

---

## ğŸš€ Quick Start Commands

**For someone with a powerful machine who wants to run everything:**

```bash
# 1. Setup (5 min)
pip install -r requirements.txt
python verify_setup.py

# 2. Run all experiments (6-8 hours, can run overnight)
python cifar10_tinycnn.py
python quanvolutional_preprocessing.py --local --num-samples 10000 --visualize
python train_quanvolutional_cnn.py --epochs 15
python quantum_hybrid_cnn_optimized.py --local --epochs 5 --quantum-qubits 8 --batch-size 16

# 3. Generate report (1 min)
python compare_and_visualize.py

# 4. Check results
cat experiments/analysis/summary_report.txt
```

---

## ğŸ“ Contact

If you encounter issues:
1. Check `verify_setup.py` output
2. Review error messages carefully
3. Try with smaller datasets first
4. Check system resources (RAM, disk space)

---

## ğŸ“ Understanding the Results

### If Quantum Wins:
- Demonstrates quantum advantage in feature extraction
- Quantum preprocessing extracts features classical can't
- Publishable result!

### If Classical Wins:
- Still valuable negative result
- Shows limitations of current quantum approaches
- Guides future research

### Either Way:
- You've implemented cutting-edge quantum ML
- Comprehensive comparison of approaches
- Solid experimental methodology

---

## ğŸŒŸ Good Luck!

You have everything you need to run comprehensive quantum CNN experiments. The code is production-ready, well-documented, and scientifically sound.

**Make quantum magic happen!** ğŸ”¬âœ¨
